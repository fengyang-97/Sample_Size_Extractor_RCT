{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate annotation dataframe from brat annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_OTHER_ANNO = 'O'\n",
    "STANDOFF_ENTITY_PREFIX = 'T'\n",
    "STANDOFF_RELATION_PREFIX = 'R'\n",
    "DATA_DIRECTORY = 'data/example_abstract_and_ann'\n",
    "ann_data_files = [f for f in listdir(DATA_DIRECTORY) if isfile(join(DATA_DIRECTORY, f)) and f.split('.')[1] == 'ann']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get one annotation dataframe\n",
    "entities = []\n",
    "relations = []\n",
    "for file in ann_data_files:\n",
    "    pmid = file.split('-')[1].split('.')[0]\n",
    "    with open(join(DATA_DIRECTORY, file), 'r') as document_anno_file:\n",
    "\n",
    "            lines = document_anno_file.readlines()\n",
    "            for line in lines:\n",
    "                standoff_line_0 = line.split('\\t')\n",
    "                standoff_line_1 = standoff_line_0[1].split()\n",
    "                if standoff_line_0[0][0] == STANDOFF_ENTITY_PREFIX:\n",
    "                    entity = {}\n",
    "                    entity['pmid'] = pmid\n",
    "                    entity['standoff_id'] = int(standoff_line_0[0][1:])\n",
    "                    #standoff_line_1 = standoff_line_0[1].split()\n",
    "                    entity['entity_type'] = standoff_line_1[0].capitalize()\n",
    "                    entity['offset_start'] = int(standoff_line_1[1])\n",
    "                    entity['offset_end'] = int(standoff_line_1[2])\n",
    "                    entity['word'] = standoff_line_0[2].split('\\n')[0]\n",
    "                    entities.append(entity)\n",
    "\n",
    "                elif standoff_line_0[0][0] == STANDOFF_RELATION_PREFIX:\n",
    "                    relation = {}\n",
    "                    relation['pmid'] = pmid\n",
    "                    relation['standoff_id'] = int(standoff_line_0[0][1:])\n",
    "                    relation['name'] = standoff_line_1[0]\n",
    "                    relation['standoff_entity1_id'] = int(standoff_line_1[1].split(':')[1][1:])\n",
    "                    relation['standoff_entity2_id'] = int(standoff_line_1[2].split(':')[1][1:])\n",
    "                    relations.append(relation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_entity_df = pd.DataFrame(entities)\n",
    "all_relation_df = pd.DataFrame(relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pmid</th>\n",
       "      <th>standoff_id</th>\n",
       "      <th>entity_type</th>\n",
       "      <th>offset_start</th>\n",
       "      <th>offset_end</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32673060</td>\n",
       "      <td>2</td>\n",
       "      <td>Year</td>\n",
       "      <td>389</td>\n",
       "      <td>393</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32673060</td>\n",
       "      <td>3</td>\n",
       "      <td>Population_info</td>\n",
       "      <td>539</td>\n",
       "      <td>574</td>\n",
       "      <td>Symptomatic, nonhospitalized adults</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32673060</td>\n",
       "      <td>4</td>\n",
       "      <td>Population_info</td>\n",
       "      <td>580</td>\n",
       "      <td>630</td>\n",
       "      <td>laboratory-confirmed COVID-19 or probable COVI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32673060</td>\n",
       "      <td>5</td>\n",
       "      <td>Population_info</td>\n",
       "      <td>635</td>\n",
       "      <td>684</td>\n",
       "      <td>high-risk exposure within 4 days of symptom onset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32673060</td>\n",
       "      <td>6</td>\n",
       "      <td>Total_sample_size</td>\n",
       "      <td>1080</td>\n",
       "      <td>1083</td>\n",
       "      <td>423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pmid  standoff_id        entity_type  offset_start  offset_end  \\\n",
       "0  32673060            2               Year           389         393   \n",
       "1  32673060            3    Population_info           539         574   \n",
       "2  32673060            4    Population_info           580         630   \n",
       "3  32673060            5    Population_info           635         684   \n",
       "4  32673060            6  Total_sample_size          1080        1083   \n",
       "\n",
       "                                                word  \n",
       "0                                               2020  \n",
       "1                Symptomatic, nonhospitalized adults  \n",
       "2  laboratory-confirmed COVID-19 or probable COVI...  \n",
       "3  high-risk exposure within 4 days of symptom onset  \n",
       "4                                                423  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_entity_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_entity_df.to_csv('data/example_abstract_and_ann/all_ann_entity.csv')\n",
    "#all_relation_df.to_csv('data/example_abstract_and_ann/all_ann_relation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary version\n",
    "all_entity = {}\n",
    "all_relation = {}\n",
    "for file in ann_data_files:\n",
    "    entities = []\n",
    "    relations = []\n",
    "    pmid = file.split('-')[1].split('.')[0]\n",
    "    with open(join(DATA_DIRECTORY, file), 'r') as document_anno_file:\n",
    "\n",
    "            lines = document_anno_file.readlines()\n",
    "            for line in lines:\n",
    "                standoff_line_0 = line.split('\\t')\n",
    "                standoff_line_1 = standoff_line_0[1].split()\n",
    "                if standoff_line_0[0][0] == STANDOFF_ENTITY_PREFIX:\n",
    "                    entity = {}\n",
    "                    #entity['pmid'] = pmid\n",
    "                    entity['standoff_id'] = int(standoff_line_0[0][1:])\n",
    "                    #standoff_line_1 = standoff_line_0[1].split()\n",
    "                    entity['entity_type'] = standoff_line_1[0].capitalize()\n",
    "                    entity['offset_start'] = int(standoff_line_1[1])\n",
    "                    entity['offset_end'] = int(standoff_line_1[2])\n",
    "                    entity['word'] = standoff_line_0[2].split('\\n')[0]\n",
    "                    entities.append(entity)\n",
    "\n",
    "                elif standoff_line_0[0][0] == STANDOFF_RELATION_PREFIX:\n",
    "                    relation = {}\n",
    "                    relation['standoff_id'] = int(standoff_line_0[0][1:])\n",
    "                    relation['name'] = standoff_line_1[0]\n",
    "                    relation['standoff_entity1_id'] = int(standoff_line_1[1].split(':')[1][1:])\n",
    "                    relation['standoff_entity2_id'] = int(standoff_line_1[2].split(':')[1][1:])\n",
    "                    relations.append(relation)\n",
    "    all_entity[pmid] = entities\n",
    "    all_relation[pmid] = relations\n",
    "    \n",
    "with open('data/example_abstract_and_ann/all_ann_entity.pickle', 'wb') as handle:\n",
    "    pickle.dump(all_entity, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Focus on sample size entities and convert numbers in text into integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_ss_df = all_entity_df[all_entity_df['entity_type'] == 'Total_sample_size']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We provide two options for transforming the number into integers.\n",
    "\n",
    "- word2number.w2n: a package to transform word into numbers.\n",
    "- Our defined processer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 1: word2number.w2n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from word2number import w2n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_ss_word_to_num(x):\n",
    "    if x[0].isalpha():\n",
    "        x_r = x.replace('\\u2009',' ').replace('\\u2008',' ').replace('\\xa0',' ').replace('\\u202f',' ')\n",
    "    else:\n",
    "        x_r = x.replace(' ','').replace(',','').replace('\\u2009','').replace('\\u2008','').replace('\\xa0','').replace('\\u202f','')\n",
    "    \n",
    "    try:\n",
    "        num = int(w2n.word_to_num(x_r))\n",
    "    except:\n",
    "        num = None\n",
    "    return num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fengyanglin/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "tt_ss_df['tt_sample_size'] = tt_ss_df['word'].apply(convert_ss_word_to_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pmid</th>\n",
       "      <th>standoff_id</th>\n",
       "      <th>entity_type</th>\n",
       "      <th>offset_start</th>\n",
       "      <th>offset_end</th>\n",
       "      <th>word</th>\n",
       "      <th>tt_sample_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32673060</td>\n",
       "      <td>6</td>\n",
       "      <td>Total_sample_size</td>\n",
       "      <td>1080</td>\n",
       "      <td>1083</td>\n",
       "      <td>423</td>\n",
       "      <td>423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>33306283</td>\n",
       "      <td>11</td>\n",
       "      <td>Total_sample_size</td>\n",
       "      <td>665</td>\n",
       "      <td>669</td>\n",
       "      <td>1033</td>\n",
       "      <td>1033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>32641343</td>\n",
       "      <td>1</td>\n",
       "      <td>Total_sample_size</td>\n",
       "      <td>1129</td>\n",
       "      <td>1132</td>\n",
       "      <td>308</td>\n",
       "      <td>308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>33085857</td>\n",
       "      <td>4</td>\n",
       "      <td>Total_sample_size</td>\n",
       "      <td>1110</td>\n",
       "      <td>1113</td>\n",
       "      <td>243</td>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>33332779</td>\n",
       "      <td>33</td>\n",
       "      <td>Total_sample_size</td>\n",
       "      <td>911</td>\n",
       "      <td>914</td>\n",
       "      <td>389</td>\n",
       "      <td>389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>33332778</td>\n",
       "      <td>1</td>\n",
       "      <td>Total_sample_size</td>\n",
       "      <td>1115</td>\n",
       "      <td>1118</td>\n",
       "      <td>275</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>33113295</td>\n",
       "      <td>2</td>\n",
       "      <td>Total_sample_size</td>\n",
       "      <td>526</td>\n",
       "      <td>529</td>\n",
       "      <td>452</td>\n",
       "      <td>452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>32706953</td>\n",
       "      <td>23</td>\n",
       "      <td>Total_sample_size</td>\n",
       "      <td>1207</td>\n",
       "      <td>1210</td>\n",
       "      <td>504</td>\n",
       "      <td>504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>33301246</td>\n",
       "      <td>3</td>\n",
       "      <td>Total_sample_size</td>\n",
       "      <td>939</td>\n",
       "      <td>945</td>\n",
       "      <td>43,448</td>\n",
       "      <td>43448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pmid  standoff_id        entity_type  offset_start  offset_end  \\\n",
       "4   32673060            6  Total_sample_size          1080        1083   \n",
       "18  33306283           11  Total_sample_size           665         669   \n",
       "22  32641343            1  Total_sample_size          1129        1132   \n",
       "31  33085857            4  Total_sample_size          1110        1113   \n",
       "57  33332779           33  Total_sample_size           911         914   \n",
       "65  33332778            1  Total_sample_size          1115        1118   \n",
       "73  33113295            2  Total_sample_size           526         529   \n",
       "87  32706953           23  Total_sample_size          1207        1210   \n",
       "91  33301246            3  Total_sample_size           939         945   \n",
       "\n",
       "      word  tt_sample_size  \n",
       "4      423             423  \n",
       "18    1033            1033  \n",
       "22     308             308  \n",
       "31     243             243  \n",
       "57     389             389  \n",
       "65     275             275  \n",
       "73     452             452  \n",
       "87     504             504  \n",
       "91  43,448           43448  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt_ss_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save ann results and generate total sample size labeled results\n",
    "all_pmid_list = []\n",
    "for file in ann_data_files:\n",
    "    pmid = file.split('-')[1].split('.')[0]\n",
    "    all_pmid_list.append(pmid)\n",
    "tt_ss_df_save = tt_ss_df[['pmid','tt_sample_size']].merge(pd.DataFrame({'pmid':all_pmid_list}), \n",
    "                                                          how='right', on='pmid')\n",
    "tt_ss_df_save.to_csv('data/example_abstract_and_ann/ann_tt_sample_size.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pmid</th>\n",
       "      <th>tt_sample_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32673060</td>\n",
       "      <td>423.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33306283</td>\n",
       "      <td>1033.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32641343</td>\n",
       "      <td>308.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33085857</td>\n",
       "      <td>243.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33332779</td>\n",
       "      <td>389.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>33332778</td>\n",
       "      <td>275.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>33113295</td>\n",
       "      <td>452.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>32706953</td>\n",
       "      <td>504.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>33301246</td>\n",
       "      <td>43448.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>32678530</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pmid  tt_sample_size\n",
       "0  32673060           423.0\n",
       "1  33306283          1033.0\n",
       "2  32641343           308.0\n",
       "3  33085857           243.0\n",
       "4  33332779           389.0\n",
       "5  33332778           275.0\n",
       "6  33113295           452.0\n",
       "7  32706953           504.0\n",
       "8  33301246         43448.0\n",
       "9  32678530             NaN"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt_ss_df_save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 2: Designed number transformer. (the same one used in model training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import index_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sse_str_to_num(x):\n",
    "    try:\n",
    "        num = int(x)\n",
    "    except:\n",
    "        num = x\n",
    "    return num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fengyanglin/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/fengyanglin/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "tt_ss_df['tt_sample_size2'] = tt_ss_df['word'].apply(index_numbers.NumberTagger().swap) #str\n",
    "tt_ss_df['tt_sample_size2_num'] = tt_ss_df['tt_sample_size2'].apply(sse_str_to_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pmid</th>\n",
       "      <th>standoff_id</th>\n",
       "      <th>entity_type</th>\n",
       "      <th>offset_start</th>\n",
       "      <th>offset_end</th>\n",
       "      <th>word</th>\n",
       "      <th>tt_sample_size</th>\n",
       "      <th>tt_sample_size2</th>\n",
       "      <th>tt_sample_size2_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32673060</td>\n",
       "      <td>6</td>\n",
       "      <td>Total_sample_size</td>\n",
       "      <td>1080</td>\n",
       "      <td>1083</td>\n",
       "      <td>423</td>\n",
       "      <td>423</td>\n",
       "      <td>423</td>\n",
       "      <td>423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>33306283</td>\n",
       "      <td>11</td>\n",
       "      <td>Total_sample_size</td>\n",
       "      <td>665</td>\n",
       "      <td>669</td>\n",
       "      <td>1033</td>\n",
       "      <td>1033</td>\n",
       "      <td>1033</td>\n",
       "      <td>1033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>32641343</td>\n",
       "      <td>1</td>\n",
       "      <td>Total_sample_size</td>\n",
       "      <td>1129</td>\n",
       "      <td>1132</td>\n",
       "      <td>308</td>\n",
       "      <td>308</td>\n",
       "      <td>308</td>\n",
       "      <td>308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>33085857</td>\n",
       "      <td>4</td>\n",
       "      <td>Total_sample_size</td>\n",
       "      <td>1110</td>\n",
       "      <td>1113</td>\n",
       "      <td>243</td>\n",
       "      <td>243</td>\n",
       "      <td>243</td>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>33332779</td>\n",
       "      <td>33</td>\n",
       "      <td>Total_sample_size</td>\n",
       "      <td>911</td>\n",
       "      <td>914</td>\n",
       "      <td>389</td>\n",
       "      <td>389</td>\n",
       "      <td>389</td>\n",
       "      <td>389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>33332778</td>\n",
       "      <td>1</td>\n",
       "      <td>Total_sample_size</td>\n",
       "      <td>1115</td>\n",
       "      <td>1118</td>\n",
       "      <td>275</td>\n",
       "      <td>275</td>\n",
       "      <td>275</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>33113295</td>\n",
       "      <td>2</td>\n",
       "      <td>Total_sample_size</td>\n",
       "      <td>526</td>\n",
       "      <td>529</td>\n",
       "      <td>452</td>\n",
       "      <td>452</td>\n",
       "      <td>452</td>\n",
       "      <td>452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>32706953</td>\n",
       "      <td>23</td>\n",
       "      <td>Total_sample_size</td>\n",
       "      <td>1207</td>\n",
       "      <td>1210</td>\n",
       "      <td>504</td>\n",
       "      <td>504</td>\n",
       "      <td>504</td>\n",
       "      <td>504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>33301246</td>\n",
       "      <td>3</td>\n",
       "      <td>Total_sample_size</td>\n",
       "      <td>939</td>\n",
       "      <td>945</td>\n",
       "      <td>43,448</td>\n",
       "      <td>43448</td>\n",
       "      <td>43,448</td>\n",
       "      <td>43,448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pmid  standoff_id        entity_type  offset_start  offset_end  \\\n",
       "4   32673060            6  Total_sample_size          1080        1083   \n",
       "18  33306283           11  Total_sample_size           665         669   \n",
       "22  32641343            1  Total_sample_size          1129        1132   \n",
       "31  33085857            4  Total_sample_size          1110        1113   \n",
       "57  33332779           33  Total_sample_size           911         914   \n",
       "65  33332778            1  Total_sample_size          1115        1118   \n",
       "73  33113295            2  Total_sample_size           526         529   \n",
       "87  32706953           23  Total_sample_size          1207        1210   \n",
       "91  33301246            3  Total_sample_size           939         945   \n",
       "\n",
       "      word  tt_sample_size tt_sample_size2 tt_sample_size2_num  \n",
       "4      423             423             423                 423  \n",
       "18    1033            1033            1033                1033  \n",
       "22     308             308             308                 308  \n",
       "31     243             243             243                 243  \n",
       "57     389             389             389                 389  \n",
       "65     275             275             275                 275  \n",
       "73     452             452             452                 452  \n",
       "87     504             504             504                 504  \n",
       "91  43,448           43448          43,448              43,448  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt_ss_df # the transformed number are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tt_ss_df_save2 = tt_ss_df[['pmid','tt_sample_size2_num']].merge(pd.DataFrame({'pmid':all_pmid_list}), \n",
    "#                                                          how='right', on='pmid')\n",
    "#tt_ss_df_save2.to_csv('data/example_abstract_and_ann/ann_tt_sample_size2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate a similar annotated dictionary for loose-match level\n",
    "- generate a dict, {pmid: {tt_ss: num, poss_tt_ss: [num]}}\n",
    "- based on the dict generated above, perform loose-levle match lateer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'standoff_id': 7,\n",
       " 'entity_type': 'Group_size',\n",
       " 'offset_start': 751,\n",
       " 'offset_end': 754,\n",
       " 'word': '518'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example\n",
    "all_entity['33306283'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the dictionary\n",
    "tt_poss_dict = {}\n",
    "for pmid in all_entity.keys():\n",
    "    cur_item_ls = all_entity[pmid]\n",
    "    cur_item_dict = {}\n",
    "    tt_ss = None\n",
    "    poss_ss_ls = []\n",
    "    for ent in cur_item_ls:\n",
    "        if ent['entity_type'] == 'Total_sample_size':\n",
    "            tt_ss = ent['word']\n",
    "            tt_ss = convert_ss_word_to_num(tt_ss)\n",
    "        if ent['entity_type'] == 'Poss_total_sample':\n",
    "            num = ent['word']\n",
    "            num = convert_ss_word_to_num(num)\n",
    "            poss_ss_ls.append(num)\n",
    "    \n",
    "    cur_item_dict['Total_sample_size'] = tt_ss\n",
    "    if len(poss_ss_ls)>0:\n",
    "        cur_item_dict['Poss_total_sample'] = poss_ss_ls\n",
    "    \n",
    "    tt_poss_dict[pmid] = cur_item_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Total_sample_size': 1033}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt_poss_dict['33306283']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/example_abstract_and_ann/tt_poss_dict.pickle', 'wb') as handle:\n",
    "    pickle.dump(tt_poss_dict, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix: Download abstracts from PubMed with a given list of PMID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from Bio import Entrez\n",
    "#pmid_to_extract_list = your list of PMID to extract\n",
    "#pmid_df = a df with columns: [\"PMID\", \"Title\"]\n",
    "#handle = Entrez.efetch(db=\"pubmed\", id=','.join(map(str, pmid_to_extract_list)),\n",
    "#                       rettype=\"xml\", retmode=\"text\")\n",
    "#records = Entrez.read(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloaded all the abstracts and generate txt file\n",
    "#j = 0\n",
    "#for i in range(len(pmid_to_extract_list)):\n",
    "#    pmid_ = pmid_to_extract_list[i]\n",
    "#    title_ = pmid_df[pmid_df['PMID']==pmid_]['Title'].item()\n",
    "#    pubmed_article_ = records['PubmedArticle'][i]\n",
    "#    if 'Abstract' in pubmed_article_['MedlineCitation']['Article'].keys():\n",
    "#        str_list = pubmed_article_['MedlineCitation']['Article']['Abstract']['AbstractText']\n",
    "#        result_str = 'TITLE: '+title_+'\\n'\n",
    "#        for k in range(len(str_list)):\n",
    "#            str_item = str_list[k]\n",
    "#            if len(str_item.attributes)>0:\n",
    "#                section_str = str_item.attributes['Label']+': '\n",
    "#                result_str = result_str + section_str + str_item + '\\n'\n",
    "#            else:\n",
    "#                result_str = result_str + str_item +'\\n'\n",
    "        \n",
    "#        j = j + 1\n",
    "#        file_path = 'data/example_abstract_and_ann/'+str(j)+'-'+str(pmid_)+'.txt'\n",
    "#\n",
    "#        with open (file_path, 'w') as f:\n",
    "#            f.write(result_str)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
