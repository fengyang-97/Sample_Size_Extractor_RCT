{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import Sample_Size_Extractor\n",
    "from utils import performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataframe: 400 abstracts from PubMed, Covid-Set(300) + General-Set(100)\n",
    "df_all = pd.read_csv('data/df_ab_w_tt_ss_400.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pmid</th>\n",
       "      <th>tt_sample_size</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33607104</td>\n",
       "      <td>50.0</td>\n",
       "      <td>TITLE: No clinical benefit of high dose cortic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33106170</td>\n",
       "      <td>400.0</td>\n",
       "      <td>TITLE: BCG revaccination of health workers in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32673060</td>\n",
       "      <td>423.0</td>\n",
       "      <td>TITLE: Hydroxychloroquine in Nonhospitalized A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33165621</td>\n",
       "      <td>479.0</td>\n",
       "      <td>TITLE: Effect of Hydroxychloroquine on Clinica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33619178</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>TITLE: Influence of a COVID-19 vaccine's effec...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pmid  tt_sample_size                                           abstract\n",
       "0  33607104            50.0  TITLE: No clinical benefit of high dose cortic...\n",
       "1  33106170           400.0  TITLE: BCG revaccination of health workers in ...\n",
       "2  32673060           423.0  TITLE: Hydroxychloroquine in Nonhospitalized A...\n",
       "3  33165621           479.0  TITLE: Effect of Hydroxychloroquine on Clinica...\n",
       "4  33619178          1000.0  TITLE: Influence of a COVID-19 vaccine's effec..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fengyanglin/opt/anaconda3/lib/python3.7/site-packages/keras_preprocessing/text.py:180: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n",
      "  warnings.warn('The `nb_words` argument in `Tokenizer` '\n"
     ]
    }
   ],
   "source": [
    "max_features=10000\n",
    "epochs=10 \n",
    "batch_size=32\n",
    "wvs = Sample_Size_Extractor.load_trained_w2v_model(\"PubMed-w2v.bin\")\n",
    "preprocessor = Sample_Size_Extractor.Preprocessor(max_features, wvs, df_all[\"abstract\"].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model intialized with ramdomized weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, random_state=0, shuffle=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish one fold, spend 135.89152275200013s.\n",
      "finish one fold, spend 128.24783697800103s.\n",
      "finish one fold, spend 133.26289692200044s.\n",
      "finish one fold, spend 128.8037666830005s.\n",
      "finish one fold, spend 126.7202151299989s.\n"
     ]
    }
   ],
   "source": [
    "# Generate 5-fold Cross-Validation predicted result on these 400 abstracts\n",
    "df_pred_result_all = pd.DataFrame()\n",
    "for train_index, test_index in kf.split(df_all):\n",
    "    start = timeit.default_timer()\n",
    "    df_train = df_all.loc[train_index, :]\n",
    "    df_test = df_all.loc[test_index, :]\n",
    "\n",
    "    X_tr, y_tr = Sample_Size_Extractor.generate_X_y(df_train)\n",
    "    nn_ = Sample_Size_Extractor.SampleSizeClassifier(preprocessor)\n",
    "    nn_.fit_MLP_model()\n",
    "    #nn_.model.load_weights(pre_w_path)\n",
    "\n",
    "    X_tr_fvs = nn_.featurize_for_input(X_tr)\n",
    "    nn_.model.fit(X_tr_fvs, y_tr,\n",
    "                         epochs=10, batch_size=32, verbose=0)\n",
    "    \n",
    "    pmid_list_, ss_pred_list_, conf_pred_list_ = performance.get_test_result(df_test, nn_, 0.2)\n",
    "    df_test_pred = pd.DataFrame({'pmid':pmid_list_, 'pred_ss':ss_pred_list_, 'conf': conf_pred_list_})\n",
    "    df_pred_result_all = df_pred_result_all.append(df_test_pred)\n",
    "    del nn_\n",
    "    stop = timeit.default_timer()\n",
    "    print('finish one fold, spend '+ str(stop-start)+'s.')\n",
    "\n",
    "df_pred_result_all.to_csv('data/result/pred_no_pretraining_400_5fcv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with all data and save weights\n",
    "X_tr, y_tr = Sample_Size_Extractor.generate_X_y(df_all)\n",
    "nn_ = Sample_Size_Extractor.SampleSizeClassifier(preprocessor)\n",
    "nn_.fit_MLP_model()\n",
    "X_tr_fvs = nn_.featurize_for_input(X_tr)\n",
    "nn_.model.fit(X_tr_fvs, y_tr, epochs=10, batch_size=32, verbose=0)\n",
    "pmid_list_, ss_pred_list_, conf_pred_list_ = performance.get_test_result(df_all, nn_, 0.2)\n",
    "df_test_pred = pd.DataFrame({'pmid':pmid_list_, 'pred_ss':ss_pred_list_, 'conf': conf_pred_list_})\n",
    "df_test_pred.to_csv('data/result/pred_no_pretraining_400_nocv.csv')\n",
    "nn_.model.save_weights('data/pretrained_weights/SSE_no_pretraining_with_ebmnlp.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate gold standard with fold id for evaluation\n",
    "# define a df listing fold id\n",
    "train_index_dict = {}\n",
    "test_index_dict = {}\n",
    "i = 0\n",
    "for train_index, test_index in kf.split(df_all):\n",
    "    train_index_dict[i] = train_index\n",
    "    test_index_dict[i] = test_index\n",
    "    i = i+1\n",
    "\n",
    "pmid_ls = []\n",
    "tt_ss_ls = []\n",
    "fold_id_ls = []\n",
    "for i in test_index_dict.keys():\n",
    "    cur_test_index = test_index_dict[i]\n",
    "    cur_df = df_all.loc[cur_test_index, ]\n",
    "    pmid_ls = pmid_ls + list(cur_df['pmid'])\n",
    "    tt_ss_ls = tt_ss_ls +list(cur_df['tt_sample_size'])\n",
    "    fold_id_ls = fold_id_ls + [i]*len(cur_df)\n",
    "\n",
    "gold_w_foldid_df = pd.DataFrame({'pmid': pmid_ls, 'tt_sample_size': tt_ss_ls, 'fold_id':fold_id_ls})\n",
    "gold_w_foldid_df.to_csv('data/result/gold_w_foldid.csv')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model intialized with pretrained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish one fold, spend 123.02742466000018s.\n",
      "finish one fold, spend 120.21527635699931s.\n",
      "finish one fold, spend 121.16634548199909s.\n",
      "finish one fold, spend 120.16461057500055s.\n",
      "finish one fold, spend 124.96583413400003s.\n"
     ]
    }
   ],
   "source": [
    "pre_w_path = 'data/pretrained_weights/p2_wo_es_32.h5'\n",
    "df_pred_result_all = pd.DataFrame()\n",
    "for train_index, test_index in kf.split(df_all):\n",
    "    start = timeit.default_timer()\n",
    "    df_train = df_all.loc[train_index, :]\n",
    "    df_test = df_all.loc[test_index, :]\n",
    "\n",
    "    X_tr, y_tr = Sample_Size_Extractor.generate_X_y(df_train)\n",
    "    nn_ = Sample_Size_Extractor.SampleSizeClassifier(preprocessor)\n",
    "    nn_.fit_MLP_model()\n",
    "    nn_.model.load_weights(pre_w_path)\n",
    "\n",
    "    X_tr_fvs = nn_.featurize_for_input(X_tr)\n",
    "    nn_.model.fit(X_tr_fvs, y_tr,\n",
    "                         epochs=10, batch_size=32, verbose=0)\n",
    "    \n",
    "    pmid_list_, ss_pred_list_, conf_pred_list_ = performance.get_test_result(df_test, nn_, 0.2)\n",
    "    df_test_pred = pd.DataFrame({'pmid':pmid_list_, 'pred_ss':ss_pred_list_, 'conf': conf_pred_list_})\n",
    "    df_pred_result_all = df_pred_result_all.append(df_test_pred)\n",
    "    del nn_\n",
    "    stop = timeit.default_timer()\n",
    "    print('finish one fold, spend '+ str(stop-start)+'s.')\n",
    "\n",
    "df_pred_result_all.to_csv('data/result/pred_pretraining_400_5fcv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with all data and save weights\n",
    "X_tr, y_tr = Sample_Size_Extractor.generate_X_y(df_all)\n",
    "nn_ = Sample_Size_Extractor.SampleSizeClassifier(preprocessor)\n",
    "nn_.fit_MLP_model()\n",
    "nn_.model.load_weights(pre_w_path)\n",
    "X_tr_fvs = nn_.featurize_for_input(X_tr)\n",
    "nn_.model.fit(X_tr_fvs, y_tr, epochs=10, batch_size=32, verbose=0)\n",
    "pmid_list_, ss_pred_list_, conf_pred_list_ = performance.get_test_result(df_all, nn_, 0.2)\n",
    "df_test_pred = pd.DataFrame({'pmid':pmid_list_, 'pred_ss':ss_pred_list_, 'conf': conf_pred_list_})\n",
    "df_test_pred.to_csv('data/result/pred_pretraining_400_nocv.csv')\n",
    "nn_.model.save_weights('data/pretrained_weights/SSE_pretraining_with_ebmnlp.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the preprocessor\n",
    "# with open('data/preprocessor.pickle', 'wb') as handle:\n",
    "#    pickle.dump(preprocessor, handle)\n",
    "# save all text in abstract for future preprocessor\n",
    "with open('data/400_abstract_text.pickle', 'wb') as handle:\n",
    "    pickle.dump(df_all[\"abstract\"].values, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract total sample size for any RCT abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input: your dataframe should have at least two columns: 'pmid', 'abstract'\n",
    "df_to_extract = df_all[['pmid', 'abstract']].iloc[0:20, ]\n",
    "df_to_extract.to_csv('data/sample_input.csv', index = False)\n",
    "#df_to_extract = pd.read_csv('data/sample_input.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pmid</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33607104</td>\n",
       "      <td>TITLE: No clinical benefit of high dose cortic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33106170</td>\n",
       "      <td>TITLE: BCG revaccination of health workers in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32673060</td>\n",
       "      <td>TITLE: Hydroxychloroquine in Nonhospitalized A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33165621</td>\n",
       "      <td>TITLE: Effect of Hydroxychloroquine on Clinica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33619178</td>\n",
       "      <td>TITLE: Influence of a COVID-19 vaccine's effec...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pmid                                           abstract\n",
       "0  33607104  TITLE: No clinical benefit of high dose cortic...\n",
       "1  33106170  TITLE: BCG revaccination of health workers in ...\n",
       "2  32673060  TITLE: Hydroxychloroquine in Nonhospitalized A...\n",
       "3  33165621  TITLE: Effect of Hydroxychloroquine on Clinica...\n",
       "4  33619178  TITLE: Influence of a COVID-19 vaccine's effec..."
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_to_extract.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all text in pretrained abstract for initializing the preprocessor\n",
    "with open('data/400_abstract_text.pickle', 'rb') as handle:\n",
    "    prev_abstract_text = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use our sample size extractor\n",
    "pre_w_path = 'data/pretrained_weights/SSE_pretraining_with_ebmnlp.h5'\n",
    "max_features=10000\n",
    "epochs=10 \n",
    "batch_size=32\n",
    "\n",
    "#wvs was loaded before\n",
    "#wvs = Sample_Size_Extractor.load_trained_w2v_model(\"PubMed-w2v.bin\")\n",
    "p_all_text = list(prev_abstract_text)+list(df_to_extract[\"abstract\"].values)\n",
    "preprocessor = Sample_Size_Extractor.Preprocessor(max_features, wvs, p_all_text)\n",
    "\n",
    "nn_ = Sample_Size_Extractor.SampleSizeClassifier(preprocessor)\n",
    "# load our trained model\n",
    "nn_.fit_MLP_model()\n",
    "nn_.model.load_weights(pre_w_path)\n",
    "pmid_list_, ss_pred_list_, conf_pred_list_ = performance.get_test_result(df_to_extract, nn_, 0.2)\n",
    "df_test_pred = pd.DataFrame({'pmid':pmid_list_, 'pred_ss':ss_pred_list_, 'conf': conf_pred_list_})\n",
    "df_test_pred.to_csv('data/sample_output.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pmid</th>\n",
       "      <th>pred_ss</th>\n",
       "      <th>conf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33607104</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.602764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33106170</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.584205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32673060</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.757549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33165621</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.884804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33619178</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.746485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>33246499</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>33568628</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.756690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>33596857</td>\n",
       "      <td>4099.0</td>\n",
       "      <td>0.491054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>33306283</td>\n",
       "      <td>1033.0</td>\n",
       "      <td>0.682457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>32627205</td>\n",
       "      <td>1584.0</td>\n",
       "      <td>0.970726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pmid  pred_ss      conf\n",
       "0  33607104     50.0  0.602764\n",
       "1  33106170    400.0  0.584205\n",
       "2  32673060     10.0  0.757549\n",
       "3  33165621    102.0  0.884804\n",
       "4  33619178      3.0  0.746485\n",
       "5  33246499      NaN       NaN\n",
       "6  33568628    100.0  0.756690\n",
       "7  33596857   4099.0  0.491054\n",
       "8  33306283   1033.0  0.682457\n",
       "9  32627205   1584.0  0.970726"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_pred.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix: pretraining with EBM-NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_ebm: a dataframe generated with sample size information from EBM-NLP corpus\n",
    "#df_ebm = pd.read_csv('ebm_df_ab_w_tt_ss.csv', index_col=0)\n",
    "#p2 = Sample_Size_Extractor.Preprocessor(max_features, wvs, df_ebm[\"abstract\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_to_train = df_ebm.copy()\n",
    "#X_tr, y_tr = Sample_Size_Extractor.generate_X_y(df_to_train)\n",
    "#nn_ = Sample_Size_Extractor.SampleSizeClassifier(p2)\n",
    "#nn_.fit_MLP_model()\n",
    "#X_tr_fvs = nn_.featurize_for_input(X_tr)\n",
    "#nn_.model.fit(X_tr_fvs, y_tr,\n",
    "#                     epochs=10, batch_size=64, validation_split=0.1)\n",
    "#nn_.model.save_weights('data/pretrained_weights/pretraining_weights_ebmnlp.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}